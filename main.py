import requests
import base64
import json
from Crypto.Cipher import AES
import time
from urllib.parse import quote
import random
import os
from datetime import datetime, timezone, timedelta
from openpyxl import Workbook
from openpyxl.styles import (
    Font, Alignment, Border, Side, PatternFill, Color
)
from openpyxl.utils import get_column_letter
from openpyxl.workbook.properties import WorkbookProperties
# é…ç½®å¸¸é‡
HEADERS = {
    "Accept": "application/json",
    "Accept-Encoding": "gzip, deflate, br",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,vi;q=0.7",
    "Connection": "keep-alive",
    "Content-Type": "application/json; charset=utf-8",
    "Host": "106.15.60.27:22222",
    "Referer": "http://106.15.60.27:22222/xxgs/",
    "Sec-Ch-Ua": '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
    "Sec-Ch-Ua-Mobile": "?0",
    "Sec-Ch-Ua-Platform": '"Windows"',
    "Sec-Fetch-Dest": "empty",
    "Sec-Fetch-Mode": "cors",
    "Sec-Fetch-Site": "same-origin",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.6261.95 Safari/537.36"
}

RETRY_COUNT = 3               # è¯·æ±‚é‡è¯•æ¬¡æ•°
PAGE_RETRY_MAX = 2           # å•é¡µæœ€å¤§é‡è¯•æ¬¡æ•°
TIMEOUT = 15                  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
PAGE_SIZE = 10

# AESé…ç½®
AES_KEY = b"6875616E6779696E6875616E6779696E"
AES_IV = b"sskjKingFree5138"

def safe_request(session: requests.Session, url: str) -> requests.Response:
    """å¸¦è‡ªåŠ¨é‡è¯•çš„å®‰å…¨è¯·æ±‚"""
    for attempt in range(RETRY_COUNT):
        try:
            if attempt > 0:
                time.sleep(random.uniform(0.5, 2.5))
            print(f"æ­£åœ¨è¯·æ±‚: {url}")  # æ·»åŠ è¯·æ±‚URLæ—¥å¿—
            response = session.get(url, headers=HEADERS, timeout=TIMEOUT)
            response.raise_for_status()
            return response
        except requests.exceptions.Timeout:
            print(f"â†º è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯• ({attempt+1}/{RETRY_COUNT})...")
        except requests.exceptions.RequestException as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")  # æ‰“å°å…·ä½“å¼‚å¸¸ä¿¡æ¯
            if attempt < RETRY_COUNT - 1:
                print(f"æ­£åœ¨è¿›è¡Œç¬¬ {attempt+2} æ¬¡å°è¯•...")
    raise RuntimeError(f"è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•° ({RETRY_COUNT})")

def aes_decrypt_base64(encrypted_base64: str) -> str:
    """å¢å¼ºç‰ˆAESè§£å¯†å‡½æ•°"""
    if not encrypted_base64:
        raise ValueError("åŠ å¯†æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è§£å¯†")

    try:
        encrypted_bytes = base64.b64decode(encrypted_base64)
        cipher = AES.new(AES_KEY, AES.MODE_CBC, AES_IV)
        decrypted_bytes = cipher.decrypt(encrypted_bytes)
        return decrypted_bytes.rstrip(b'\x00').decode("utf-8")
    except Exception as e:
        print(f"è§£å¯†å¤±è´¥ï¼ŒåŸå§‹æ•°æ®: {encrypted_base64[:50]}...")  # æ‰“å°éƒ¨åˆ†åŸå§‹æ•°æ®
        raise RuntimeError(f"è§£å¯†å¤±è´¥: {str(e)}")

def get_new_code(session: requests.Session) -> tuple:
    """è·å–æ–°éªŒè¯ç å’Œæ—¶é—´æˆ³"""
    timestamp = str(int(time.time() * 1000))
    code_url = f"http://106.15.60.27:22222/ycdc/bakCmisYcOrgan/getCreateCode?codeValue={timestamp}"

    try:
        response = safe_request(session, code_url).json()
        print(f"éªŒè¯ç æ¥å£å“åº”: {json.dumps(response, ensure_ascii=False)[:100]}...")  # æ‰“å°éƒ¨åˆ†å“åº”
        if response.get("code") != 0:
            raise RuntimeError(f"éªŒè¯ç æ¥å£å¼‚å¸¸: {response}")
        return aes_decrypt_base64(response["data"]), timestamp
    except Exception as e:
        print(f"è·å–éªŒè¯ç å¤±è´¥ï¼ŒURL: {code_url}")  # æ‰“å°å¤±è´¥çš„URL
        raise RuntimeError(f"è·å–æ–°éªŒè¯ç å¤±è´¥: {str(e)}")

def parse_response_data(encrypted_data: str) -> dict:
    """å¥å£®çš„æ•°æ®è§£ææ–¹æ³•"""
    if not encrypted_data:
        print("è­¦å‘Š: æ”¶åˆ°ç©ºçš„åŠ å¯†æ•°æ®")  # æ·»åŠ è­¦å‘Šæ—¥å¿—
        return {"error": "empty data"}

    try:
        decrypted_str = aes_decrypt_base64(encrypted_data)
        print(f"è§£å¯†åçš„æ•°æ®æ ·æœ¬: {decrypted_str[:100]}...")  # æ‰“å°è§£å¯†åçš„æ•°æ®æ ·æœ¬
        return json.loads(decrypted_str)
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯ï¼Œæ•°æ®æ ·æœ¬: {encrypted_data[:50]}...")  # æ‰“å°é”™è¯¯æ•°æ®æ ·æœ¬
        return {"error": f"invalid json format: {str(e)}"}
    except Exception as e:
        return {"error": str(e)}

def process_page(session: requests.Session, page: int, code: str, timestamp: str) -> tuple:
    """å¤„ç†å•ä¸ªé¡µé¢å¹¶è¿”å›æ•°æ®ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
    max_retries = 3
    current_code = code
    current_timestamp = timestamp

    for attempt in range(max_retries + 1):
        page_url = (
            "http://106.15.60.27:22222/ycdc/bakCmisYcOrgan/getCurrentIntegrityPage"
            f"?pageSize={PAGE_SIZE}&cioName=%E5%85%AC%E5%8F%B8&page={page}"
            f"&code={quote(current_code)}&codeValue={current_timestamp}"
        )

        try:
            # å‘é€å¸¦å½“å‰å‚æ•°çš„è¯·æ±‚
            response = safe_request(session, page_url)
            page_response = response.json()
            status = page_response.get('code', 'æœªçŸ¥')
            print(f"ç¬¬ {page} é¡µ è¯·æ±‚#{attempt+1} å“åº”çŠ¶æ€: {status}")

            # ç©ºæ•°æ®æ£€æŸ¥
            if "data" not in page_response or not page_response["data"]:
                print(f"ç©ºæ•°æ®å“åº”ï¼Œå‡†å¤‡é‡è¯•ï¼ˆå‰©ä½™é‡è¯•æ¬¡æ•°: {max_retries - attempt}ï¼‰")
                if attempt < max_retries:# é‡è¯•ä¸‰æ¬¡
                    response = safe_request(session, page_url)
                    page_response = response.json()
                    continue
                raise RuntimeError("è¿ç»­ç©ºå“åº”ï¼Œç»ˆæ­¢é‡è¯•")

            # æ•°æ®è§£æ
            page_data = parse_response_data(page_response["data"])
            
            records = page_data.get("data", [])
            print(f"ç¬¬ {page} é¡µè§£æå‡º {len(records)} æ¡è®°å½•")  # æ˜ç¡®è®°å½•æ•°é‡
            
            # æ£€æŸ¥è§£æå‡ºçš„æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            if not records:
                print(f"è­¦å‘Š: ç¬¬ {page} é¡µè§£æå‡ºç©ºè®°å½•åˆ—è¡¨")
                
            return records, page_data.get("total", 0)
        except Exception as e:
            print(f"ç¬¬ {page} é¡µå¤„ç†å¤±è´¥: {str(e)}")
            raise

    raise RuntimeError("è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")

def export_to_excel(data, github_mode=False):
    """
    ä¸“ä¸šçº§Excelå¯¼å‡ºå‡½æ•°ï¼ˆå¤šå·¥ä½œè¡¨åˆ†ç±»æ’åºï¼‰
    :param data: å¾…å¯¼å‡ºæ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸æ ¼å¼
    :param github_mode: æ˜¯å¦å¯ç”¨GitHub Actionsæ¨¡å¼
    :return: ç”Ÿæˆçš„Excelæ–‡ä»¶ç»å¯¹è·¯å¾„
    """
    # ==================== åˆ—é…ç½® ====================
    COLUMNS = [
        {'id': 'cioName',    'name': 'ä¼ä¸šåç§°',   'width': 35,  'merge': True,  'align': 'left'},
        {'id': 'eqtName',    'name': 'èµ„è´¨ç±»åˆ«',   'width': 20,  'merge': True,  'align': 'center'},
        {'id': 'csf',        'name': 'åˆå§‹åˆ†',     'width': 12,  'merge': True,  'align': 'center', 'format': '0'},
        {'id': 'zzmx',       'name': 'èµ„è´¨æ˜ç»†',   'width': 50,  'merge': False, 'align': 'left'},
        {'id': 'cxdj',       'name': 'è¯šä¿¡ç­‰çº§',   'width': 12,  'merge': False, 'align': 'center'},
        {'id': 'score',      'name': 'è¯šä¿¡åˆ†å€¼',   'width': 12,  'merge': False, 'align': 'center', 'format': '0.0'},
        {'id': 'jcf',        'name': 'åŸºç¡€åˆ†',     'width': 12,  'merge': False, 'align': 'center', 'format': '0'},
        {'id': 'zxjf',       'name': 'ä¸“é¡¹åŠ åˆ†',   'width': 12,  'merge': False, 'align': 'center', 'format': '0.0'},
        {'id': 'kf',         'name': 'æ‰£åˆ†',       'width': 12,  'merge': False, 'align': 'center', 'format': '0.0'},
        {'id': 'eqlId',      'name': 'èµ„è´¨ID',     'width': 25,  'merge': False, 'align': 'center'},
        {'id': 'orgId',      'name': 'ç»„ç»‡ID',     'width': 30,  'merge': True,  'align': 'center'},
        {'id': 'cecId',      'name': 'ä¿¡ç”¨æ¡£æ¡ˆID', 'width': 30,  'merge': True,  'align': 'center'}
    ]

    # ==================== æ ·å¼é…ç½® ====================
    header_style = {
        'font': Font(bold=True, color="FFFFFF"),
        'fill': PatternFill("solid", fgColor="003366"),
        'alignment': Alignment(horizontal="center", vertical="center", wrap_text=True),  # å¢åŠ è‡ªåŠ¨æ¢è¡Œ
        'border': Border(
            left=Side(style="thin"),
            right=Side(style="thin"),
            top=Side(style="thin"),
            bottom=Side(style="thin")
        )
    }
    cell_border = Border(
        left=Side(style="thin"),
        right=Side(style="thin"),
        top=Side(style="thin"),
        bottom=Side(style="thin")
    )
    
    def get_cell_alignment(horizontal='left'):
        """åŠ¨æ€åˆ›å»ºå¯¹é½å¯¹è±¡"""
        return Alignment(
            vertical='center',
            horizontal=horizontal,
            wrap_text=True
        )
    
    # ==================== æ–°å¢JSONç”Ÿæˆé€»è¾‘ ====================
    def generate_top_json(sorted_data, category_name, github_mode):
        """ç”Ÿæˆå‰10åJSONæ•°æ®"""
        utc8_offset = timezone(timedelta(hours=8))
        timestamp = datetime.now(utc8_offset).strftime("%Y%m%d_%H%M%S")
        
        data_list = []    
        for idx, item in enumerate(sorted_data[:10], 1):
            data_list.append({
                "æ’å": idx,
                "ä¼ä¸šåç§°": item.get("cioName", ""),
                "è¯šä¿¡åˆ†å€¼": item.get("score", 0)
            })
    
        if not data_list:
            print(f"è­¦å‘Š: {category_name} æ— æ•°æ®ï¼Œè·³è¿‡JSONç”Ÿæˆ")
            return None
    
        # æ„å»ºåŒ…å«æ—¶é—´æˆ³çš„ç»“æ„
        top_data = {
            "TIMEamp": timestamp,
            "DATAlist": data_list
        }
    
        # æ„å»ºæ–‡ä»¶å
        json_filename = f"{category_name}_top10.json"
        
        if github_mode:
            output_dir = os.path.join(os.getcwd(), "excel_output")
            json_filename = os.path.join(output_dir, json_filename)
    
        # å†™å…¥æ–‡ä»¶
        try:
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(top_data, f, ensure_ascii=False, indent=2)
            print(f"å·²ç”ŸæˆJSONæ–‡ä»¶: {os.path.abspath(json_filename)}")
            return json_filename
        except Exception as e:
            print(f"JSONæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None

    # ==================== æ•°æ®å¤„ç† ====================
    def process_item(item):
        """å¼ºåŒ–æ•°æ®å¤„ç†ï¼Œç¡®ä¿å­—æ®µå­˜åœ¨"""
        if item.get('eqtName') != 'æ–½å·¥':
            return []
        
        main_info = {
            'cioName': item.get('cioName', ''),
            'eqtName': item.get('eqtName', ''),
            'csf': float(item.get('csf', 0)),
            'orgId': item.get('orgId', ''),
            'cecId': item.get('cecId', ''),
            'zzmx': ''  # ç¡®ä¿zzmxå­—æ®µå§‹ç»ˆå­˜åœ¨
        }

        details = item.get('zzmxcxfArray', [])
        if not details:
            # è¿”å›å¸¦é»˜è®¤å€¼çš„ä¸»ä¿¡æ¯
            return [main_info]
        
        processed = []
        for detail in details:
            processed.append({
                **main_info,
                'zzmx': detail.get('zzmx', ''),
                'cxdj': detail.get('cxdj', ''),
                'score': float(detail.get('score', 0)),
                'jcf': float(detail.get('jcf', 0)),
                'zxjf': float(detail.get('zxjf', 0)),
                'kf': float(detail.get('kf', 0)),
                'eqlId': detail.get('eqlId', '')
            })
        return processed

    # ç”ŸæˆåŸºç¡€æ•°æ®
    processed_data = []
    for item in data:
        if isinstance(item, dict):
            processed_data.extend(process_item(item))

    # ==================== åˆ›å»ºä¸»å·¥ä½œç°¿ ====================
    wb = Workbook()
    # æ‰‹åŠ¨åˆ›å»º UTC+8 æ—¶åŒº
    utc8_offset = timezone(timedelta(hours=8))
    timestamp = datetime.now(utc8_offset).strftime("%Y%m%d_%H%M%S")
    
    # ==================== å·¥ä½œè¡¨é…ç½® ====================
    sheet_configs = [
        {
            "name": "ä¼ä¸šä¿¡ç”¨æ•°æ®æ±‡æ€»",
            "prefix": None,
            "freeze": 'B2',
            "merge": True
        },
        {
            "name": "å»ºç­‘å·¥ç¨‹æ€»æ‰¿åŒ…ä¿¡ç”¨åˆ†æ’åº",
            "prefix": "å»ºç­‘ä¸šä¼ä¸šèµ„è´¨_æ–½å·¥æ€»æ‰¿åŒ…_å»ºç­‘å·¥ç¨‹_",
            "freeze": 'B2',
            "merge": False,
            "generate_json": True  # ğŸ¯ æ–°å¢JSONç”Ÿæˆæ ‡è®°
        },
        {
            "name": "å¸‚æ”¿å…¬ç”¨å·¥ç¨‹ä¿¡ç”¨åˆ†æ’åº",
            "prefix": "å»ºç­‘ä¸šä¼ä¸šèµ„è´¨_æ–½å·¥æ€»æ‰¿åŒ…_å¸‚æ”¿å…¬ç”¨å·¥ç¨‹_",
            "freeze": 'B2',
            "merge": False
        },
        {
            "name": "è£…ä¿®è£…é¥°å·¥ç¨‹ä¿¡ç”¨åˆ†æ’åº",
            "prefix": "å»ºç­‘ä¸šä¼ä¸šèµ„è´¨_ä¸“ä¸šæ‰¿åŒ…_å»ºç­‘è£…ä¿®è£…é¥°å·¥ç¨‹_",
            "freeze": 'B2',
            "merge": False
        }
    ]
    
    # ==================== æ–‡ä»¶è¾“å‡ºé…ç½® ====================
    output_dir = os.getcwd()
    if github_mode:
        output_dir = os.path.join(output_dir, "excel_output")
        os.makedirs(output_dir, exist_ok=True)
    
    json_files = []
    
    # ==================== æ„å»ºå„å·¥ä½œè¡¨ ====================
    # å…ˆåˆ›å»ºæ±‡æ€»è¡¨
    wb = Workbook()
    summary_sheet = wb.active
    summary_sheet.title = sheet_configs[0]["name"]
    
    # ç„¶ååˆ›å»ºå…¶ä»–å·¥ä½œè¡¨
    for config in sheet_configs[1:]:
        ws = wb.create_sheet(title=config["name"])
        print(f"å·²åˆ›å»ºå·¥ä½œè¡¨: {ws.title}")  # è°ƒè¯•æ—¥å¿—

    # ==================== å¡«å……æ¯ä¸ªå·¥ä½œè¡¨ ====================
    for config in sheet_configs:
        # è·å–å·¥ä½œè¡¨å¯¹è±¡
        if config["name"] == "ä¼ä¸šä¿¡ç”¨æ•°æ®æ±‡æ€»":
            ws = summary_sheet
        else:
            ws = wb[config["name"]]
        
        print(f"\næ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {ws.title}")  # è°ƒè¯•æ—¥å¿—
        
        # è®¾ç½®å†»ç»“çª—æ ¼
        ws.freeze_panes = config["freeze"]
        
        # ========== å†™å…¥è¡¨å¤´ ==========
        headers = [col['name'] for col in COLUMNS]
        ws.append(headers)
        print(f"è¡¨å¤´å†™å…¥å®Œæˆï¼Œè¡Œæ•°: {ws.max_row}")  # è°ƒè¯•æ—¥å¿—
        
        # åº”ç”¨è¡¨å¤´æ ·å¼
        for col_idx, col in enumerate(COLUMNS, 1):
            cell = ws.cell(row=1, column=col_idx)
            for attr, value in header_style.items():
                setattr(cell, attr, value)
            ws.column_dimensions[get_column_letter(col_idx)].width = col['width']

        # ========== å¤„ç†æ•°æ® ==========
        if config["name"] == "ä¼ä¸šä¿¡ç”¨æ•°æ®æ±‡æ€»":
            sheet_data = processed_data
            merge_map = {}
        else:
            # è¿‡æ»¤æ’åºæ•°æ®
            sheet_data = sorted(
                [d for d in processed_data 
                 if str(d.get('zzmx', '')).startswith(config["prefix"]) 
                 and 'çº§' in str(d.get('zzmx', ''))],
                key=lambda x: x.get('score', 0), 
                reverse=True
            )
            print(f"è¿‡æ»¤åˆ°æ•°æ®é‡: {len(sheet_data)}")  # è°ƒè¯•æ—¥å¿—

            # ç”ŸæˆJSONï¼ˆä»…é™æŒ‡å®šå·¥ä½œè¡¨ï¼‰
            if config.get("generate_json"):
                print(f"\næ­£åœ¨ç”Ÿæˆ {config['name']} çš„JSONæ’è¡Œæ¦œ...")
                json_path = generate_top_json(sheet_data, config["name"], output_dir)
                if json_path:
                    json_files.append(json_path)

        # ========== å†™å…¥æ•°æ® ==========
        if len(sheet_data) == 0:
            print(f"è­¦å‘Š: {config['name']} æ— æ•°æ®ï¼Œè·³è¿‡å†™å…¥")
            continue
        # ==========åˆå¹¶å•å…ƒæ ¼é€»è¾‘ï¼ˆä»…æ±‡æ€»è¡¨ï¼‰==========
        current_key = None
        start_row = 2
        
        for row_idx, row_data in enumerate(sheet_data, 2):
            # è°ƒè¯•ï¼šæ‰“å°å‰3è¡Œæ•°æ®
            if row_idx <= 4:
                print(f"å†™å…¥è¡Œ {row_idx} æ•°æ®: {row_data['zzmx'][:30]}...")
                
            # ä¼ä¸šä¿¡ç”¨æ•°æ®æ±‡æ€»éœ€è¦åˆå¹¶å•å…ƒæ ¼
            if config["merge"]:
                unique_key = f"{row_data['orgId']}-{row_data['cecId']}"
                if unique_key != current_key:
                    if current_key is not None:
                        merge_map[current_key] = (start_row, row_idx-1)
                    current_key = unique_key
                    start_row = row_idx
            
            # å†™å…¥è¡Œæ•°æ®
            row = [row_data.get(col['id'], '') for col in COLUMNS]
            ws.append(row)
            
            # è®¾ç½®å•å…ƒæ ¼æ ·å¼
            for col_idx in range(1, len(COLUMNS)+1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell.border = cell_border
                
                # è·å–åˆ—å®šä¹‰
                col_def = COLUMNS[col_idx-1]
                
                # è®¾ç½®å¯¹é½æ–¹å¼
                cell.alignment = get_cell_alignment(col_def['align'])
                
                # è®¾ç½®æ•°å­—æ ¼å¼
                if col_def.get('format'):
                    cell.number_format = col_def['format']

            # ==================== ä¼˜åŒ–åˆå¹¶å•å…ƒæ ¼æ ·å¼ ====================
            # åœ¨åˆå¹¶å•å…ƒæ ¼åå¢åŠ æ ·å¼é‡è®¾
            if config["merge"]:
                if current_key:
                    end_row = len(sheet_data) + 1
                    merge_map[current_key] = (start_row, end_row)
                
                for col in COLUMNS:
                    if col['merge']:
                        col_letter = get_column_letter(COLUMNS.index(col)+1)
                        for (start, end) in merge_map.values():
                            if end > start:
                                merge_range = f"{col_letter}{start}:{col_letter}{end}"
                                ws.merge_cells(merge_range)
                                # åŒæ­¥åˆå¹¶åŒºåŸŸæ ·å¼
                                for row in ws[merge_range]:
                                    for cell in row:
                                        cell.alignment = get_cell_alignment(col['align'])
                            

    # ==================== æœ€ç»ˆéªŒè¯ ====================
    print("\næœ€ç»ˆå·¥ä½œè¡¨åˆ—è¡¨:")
    for sheet in wb.sheetnames:
        print(f"- {sheet}")
        
    print(f"\nå„å·¥ä½œè¡¨æ•°æ®é‡:")
    for sheet in wb.worksheets:
        print(f"{sheet.title}: {sheet.max_row-1} è¡Œ")  # å‡å»è¡¨å¤´

    # ==================== æ–‡ä»¶ä¿å­˜ ====================
    filename = f"å®œæ˜Œå¸‚ä¿¡ç”¨è¯„ä»·ä¿¡æ¯_{timestamp}.xlsx" if github_mode else "å®œæ˜Œå¸‚ä¿¡ç”¨è¯„ä»·ä¿¡æ¯.xlsx"
    
    if github_mode:
        output_dir = os.path.join(os.getcwd(), "excel_output")
        # ç¡®ä¿ç›®å½•åˆ›å»ºæˆåŠŸ
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        except Exception as e:
            print(f"ç›®å½•åˆ›å»ºå¤±è´¥: {str(e)}")
            raise
        
        filename = os.path.join(output_dir, filename)
        print(f"æœ€ç»ˆä¿å­˜è·¯å¾„: {filename}")  # è·¯å¾„è°ƒè¯•

    try:
        # åˆ é™¤é»˜è®¤åˆ›å»ºçš„ç©ºç™½å·¥ä½œè¡¨
        if "Sheet" in wb.sheetnames:
            del wb["Sheet"]
            
        wb.save(filename)
        print(f"æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{os.path.abspath(filename)}")
        print("åŒ…å«çš„å·¥ä½œè¡¨:")
        for sheet in wb.sheetnames:
            print(f"- {sheet}")
            
        return {
            "excel": filename,
            "json": json_files
        }
    except Exception as e:
        print(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{str(e)}")
        import traceback
        traceback.print_exc()
        return None
        
def main():
    print("=== å¯åŠ¨æ•°æ®è·å–ç¨‹åº ===")
    session = requests.Session()
    all_data = []

    try:
        # åˆå§‹è·å–éªŒè¯ç 
        current_code, current_ts = get_new_code(session)
        print(f"[åˆå§‹åŒ–] éªŒè¯ç : {current_code} | æ—¶é—´æˆ³: {current_ts}")

        # è·å–ç¬¬ä¸€é¡µç¡®å®šæ€»æ•°
        first_data, total = process_page(session, 1, current_code, current_ts)
        #total_pages = 100 #æµ‹è¯•
        total_pages = (total + PAGE_SIZE - 1) // PAGE_SIZE
        print(f"[åˆå§‹åŒ–] æ€»è®°å½•æ•°: {total} | æ€»é¡µæ•°: {total_pages}")

        if total == 0:
            print("é”™è¯¯: APIè¿”å›æ€»è®°å½•æ•°ä¸º0ï¼Œæ— éœ€ç»§ç»­å¤„ç†")
            return

        # åˆ†é¡µå¤„ç†
        page = 1
        while page <= total_pages:
            retry_count = 0
            success = False

            while retry_count < PAGE_RETRY_MAX and not success:
                try:
                    print(f"\n[å¤„ç†ä¸­] ç¬¬ {page} é¡µ (é‡è¯•æ¬¡æ•°: {retry_count})")
                    page_data, _ = process_page(session, page, current_code, current_ts)
                    
                    if page_data:
                        print(f"[æˆåŠŸè·å–æ•°æ®] ç¬¬ {page} é¡µ {len(page_data)} æ¡è®°å½•")
                        all_data.extend(page_data)
                        success = True
                        page += 1
                    else:
                        print(f"[è­¦å‘Š] ç¬¬ {page} é¡µè·å–åˆ°ç©ºæ•°æ®ï¼Œå°è¯•åˆ·æ–°éªŒè¯ç ")
                        raise RuntimeError("empty page data")

                except Exception as e:
                    retry_count += 1
                    print(f"[é‡è¯•] ç¬¬ {page} é¡µç¬¬ {retry_count} æ¬¡é‡è¯•: {str(e)}")

                    # è·å–æ–°éªŒè¯ç 
                    try:
                        current_code, current_ts = get_new_code(session)
                        print(f"[åˆ·æ–°] æ–°éªŒè¯ç : {current_code} | æ–°æ—¶é—´æˆ³: {current_ts}")
                    except Exception as e:
                        print(f"[è­¦å‘Š] éªŒè¯ç åˆ·æ–°å¤±è´¥: {str(e)}")
                        break

            if not success:
                print(f"[ç»ˆæ­¢] ç¬¬ {page} é¡µè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æ­¤é¡µ")
                page += 1  # è·³è¿‡å¤±è´¥é¡µ

        print(f"\n=== æ•°æ®è·å–å®Œæˆ ===")
        print(f"æ€»è·å–è®°å½•æ•°: {len(all_data)}")
        
        # å¯¼å‡ºæ•°æ®å‰å†æ¬¡æ£€æŸ¥
        if all_data:
            saved_path = export_to_excel(all_data, github_mode=True)
            if saved_path:
                github_output = os.getenv('GITHUB_OUTPUT')
                if github_output:
                    with open(github_output, 'a') as f:
                        f.write(f'file-path={saved_path}\n')
                else:
                    print("::æ³¨æ„:: æœªåœ¨GitHub Actionsç¯å¢ƒä¸­ï¼Œè·³è¿‡è¾“å‡ºè®¾ç½®")
        else:
            print("é”™è¯¯: æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œæ— æ³•å¯¼å‡ºExcel")
    except Exception as e:
        print(f"\n!!! ç¨‹åºæ‰§è¡Œå¤±è´¥ !!!\né”™è¯¯åŸå› : {str(e)}")
    finally:
        session.close()

if __name__ == "__main__":
    main()
